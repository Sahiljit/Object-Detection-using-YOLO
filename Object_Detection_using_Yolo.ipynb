{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object Detection using Yolo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ih2kPszrSwO",
        "outputId": "8dc6aa3e-a802-48d2-e325-632367944c8b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGQiWGx-rvtS"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOkLL7x23fQQ"
      },
      "source": [
        "CONFIDENCE = 0.5\n",
        "SCORE_THRESHOLD = 0.5\n",
        "IOU_THRESHOLD = 0.5\n",
        "\n",
        "# the neural network configuration\n",
        "config_path = \"/content/drive/My Drive/object-detection/cfg/yolov3.cfg\"\n",
        "# the YOLO net weights file\n",
        "weights_path = \"/content/drive/My Drive/object-detection/weights/yolov3.weights\"\n",
        "# weights_path = \"weights/yolov3-tiny.weights\"\n",
        "\n",
        "# loading all the class labels (objects)\n",
        "labels = open(\"/content/drive/My Drive/object-detection/data/coco.names\").read().strip().split(\"\\n\")\n",
        "# generating colors for each object for later plotting\n",
        "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWWTIfTE4Eut"
      },
      "source": [
        "# load the YOLO network\n",
        "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_ZuN5ph4Tj4"
      },
      "source": [
        "path_name = \"/content/drive/My Drive/object-detection/images/person.jpg\"\n",
        "image = cv2.imread(path_name)\n",
        "file_name = os.path.basename(path_name)\n",
        "filename, ext = file_name.split(\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XReEtTOGCz8Z"
      },
      "source": [
        " we need to normalize, scale and reshape this image to be suitable as an input to the neural network:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTHEUDNV4br5"
      },
      "source": [
        "h, w = image.shape[:2]\n",
        "# create 4D blob\n",
        "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xibqLH6qC-Cp"
      },
      "source": [
        " feed this image into the neural network to get the output predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyVHlkyG4j0z",
        "outputId": "a44137bf-419a-48e6-b058-e18137898580"
      },
      "source": [
        "# sets the blob as the input of the network\n",
        "net.setInput(blob)\n",
        "# get all the layer names\n",
        "ln = net.getLayerNames()\n",
        "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "# feed forward (inference) and get the network output\n",
        "# measure how much it took in seconds\n",
        "start = time.perf_counter()\n",
        "layer_outputs = net.forward(ln)\n",
        "time_took = time.perf_counter() - start\n",
        "print(f\"Time took: {time_took:.2f}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time took: 2.42s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21dGnf1gDIjv"
      },
      "source": [
        "iterate over the neural network outputs and discard any object that has the confidence less than CONFIDENCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_diMV2N4lqv"
      },
      "source": [
        "font_scale = 1\n",
        "thickness = 1\n",
        "boxes, confidences, class_ids = [], [], []\n",
        "# loop over each of the layer outputs\n",
        "for output in layer_outputs:\n",
        "    # loop over each of the object detections\n",
        "    for detection in output:\n",
        "        # extract the class id (label) and confidence (as a probability) of\n",
        "        # the current object detection\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "        # discard out weak predictions by ensuring the detected\n",
        "        # probability is greater than the minimum probability\n",
        "        if confidence > CONFIDENCE:\n",
        "            # scale the bounding box coordinates back relative to the\n",
        "            # size of the image, keeping in mind that YOLO actually\n",
        "            # returns the center (x, y)-coordinates of the bounding\n",
        "            # box followed by the boxes' width and height\n",
        "            box = detection[:4] * np.array([w, h, w, h])\n",
        "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "            # use the center (x, y)-coordinates to derive the top and\n",
        "            # and left corner of the bounding box\n",
        "            x = int(centerX - (width / 2))\n",
        "            y = int(centerY - (height / 2))\n",
        "            # update our list of bounding box coordinates, confidences,\n",
        "            # and class IDs\n",
        "            boxes.append([x, y, int(width), int(height)])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N9sv_gk4s-b",
        "outputId": "c3c0bd86-ae88-4d54-bf4f-460fde86b91e"
      },
      "source": [
        "print(detection.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(85,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKwAzgB5DcLP"
      },
      "source": [
        "draw the object rectangles and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiYaVt-b4ulB"
      },
      "source": [
        "# loop over the indexes we are keeping\n",
        "for i in range(len(boxes)):\n",
        "    # extract the bounding box coordinates\n",
        "    x, y = boxes[i][0], boxes[i][1]\n",
        "    w, h = boxes[i][2], boxes[i][3]\n",
        "    # draw a bounding box rectangle and label on the image\n",
        "    color = [int(c) for c in colors[class_ids[i]]]\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), color=color, thickness=thickness)\n",
        "    text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
        "    # calculate text width & height to draw the transparent boxes as background of the text\n",
        "    (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
        "    text_offset_x = x\n",
        "    text_offset_y = y - 5\n",
        "    box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
        "    overlay = image.copy()\n",
        "    cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
        "    # add opacity (transparency to the box)\n",
        "    image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
        "    # now put the text (label: confidence %)\n",
        "    cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        fontScale=font_scale, color=(0, 0, 0), thickness=thickness)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ9tzIUM6gMu"
      },
      "source": [
        "# %matplotlib inline\n",
        "# #The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook\n",
        "# from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmEsr2B64wM9"
      },
      "source": [
        "# # cv2.imshow(\"image\", image)\n",
        "# plt.imshow(image)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzhP_7UcDqeX"
      },
      "source": [
        "Non-Maximal Suppression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBTTNyVE4yAf"
      },
      "source": [
        "# perform the non maximum suppression given the scores defined before\n",
        "idxs = cv2.dnn.NMSBoxes(boxes, confidences, SCORE_THRESHOLD, IOU_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVDUcaPp5Eki"
      },
      "source": [
        "# ensure at least one detection exists\n",
        "if len(idxs) > 0:\n",
        "    # loop over the indexes we are keeping\n",
        "    for i in idxs.flatten():\n",
        "        # extract the bounding box coordinates\n",
        "        x, y = boxes[i][0], boxes[i][1]\n",
        "        w, h = boxes[i][2], boxes[i][3]\n",
        "        # draw a bounding box rectangle and label on the image\n",
        "        color = [int(c) for c in colors[class_ids[i]]]\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), color=color, thickness=thickness)\n",
        "        text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
        "        # calculate text width & height to draw the transparent boxes as background of the text\n",
        "        (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
        "        text_offset_x = x\n",
        "        text_offset_y = y - 5\n",
        "        box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
        "        overlay = image.copy()\n",
        "        cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
        "        # add opacity (transparency to the box)\n",
        "        image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
        "        # now put the text (label: confidence %)\n",
        "        cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            fontScale=font_scale, color=(0, 0, 0), thickness=thickness)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yT7E4zb7Lvj"
      },
      "source": [
        "# plt.imshow(image)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyYEfTOi5HtR",
        "outputId": "a662cfee-5d40-4859-ff69-85d04a9f8456"
      },
      "source": [
        "cv2.imwrite(\"/content/drive/My Drive/object-detection/person.jpg\", image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJYIMKAD5JoP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}